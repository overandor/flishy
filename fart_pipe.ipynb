{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/overandor/flishy/blob/main/fart_pipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "838626fc"
      },
      "source": [
        "!pip install librosa mido --quiet\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# Parameters for the dummy audio file\n",
        "sample_rate = 44100  # samples per second\n",
        "duration = 1.0        # seconds\n",
        "frequency = 100       # Hz (low frequency to simulate a 'fart' like sound)\n",
        "\n",
        "# Generate time array\n",
        "t = np.linspace(0., duration, int(sample_rate * duration))\n",
        "\n",
        "# Generate a sine wave for the low frequency burst, with a simple envelope\n",
        "amplitude_envelope = np.exp(-5 * t) * np.sin(2 * np.pi * 2 * t) + 0.1 # Adds a little sustained noise\n",
        "sound_wave = 0.5 * np.sin(2 * np.pi * frequency * t) * amplitude_envelope\n",
        "\n",
        "# Normalize to 16-bit integer range\n",
        "audio_data = (sound_wave * 32767).astype(np.int16)\n",
        "\n",
        "# Save the dummy audio file\n",
        "file_name = \"dummy_fart.wav\"\n",
        "wavfile.write(file_name, sample_rate, audio_data)\n",
        "\n",
        "print(f\"✅ Generated dummy audio file: {file_name}\")\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "from mido import Message, MidiFile, MidiTrack\n",
        "import os\n",
        "\n",
        "# --- Configuration --- #\n",
        "AUDIO_FILE = \"dummy_fart.wav\"\n",
        "MIDI_FILE = \"fart_midi.mid\"\n",
        "SAMPLE_RATE = 44100 # Ensure this matches the dummy audio generation\n",
        "\n",
        "# 'Fart' detection parameters (can be tuned)\n",
        "amplitude_threshold = 0.1 # Adjust based on normalized audio\n",
        "low_freq_band_min = 20    # Hz\n",
        "low_freq_band_max = 200   # Hz\n",
        "\n",
        "# MIDI mapping parameters\n",
        "midi_note_base = 36 # C2 - a low MIDI note for farts\n",
        "midi_velocity_min = 60\n",
        "midi_velocity_max = 100\n",
        "\n",
        "# --- 1. Load Audio ---\n",
        "if not os.path.exists(AUDIO_FILE):\n",
        "    print(f\"Error: Audio file '{AUDIO_FILE}' not found. Please ensure it has been generated.\")\n",
        "    # Re-generate dummy_fart.wav if not found to ensure the task can proceed\n",
        "    # This part assumes you might want to re-run the dummy generation if the file is missing\n",
        "    # For this execution, we assume it exists as per previous output.\n",
        "    raise FileNotFoundError(f\"Audio file '{AUDIO_FILE}' is missing.\")\n",
        "\n",
        "audio, sr = librosa.load(AUDIO_FILE, sr=SAMPLE_RATE) # Ensure sample rate matches creation\n",
        "print(f\"✅ Loaded audio file: {AUDIO_FILE} with sample rate {sr}\")\n",
        "\n",
        "# --- 2. Basic 'Fart' Detection and 3. Feature Extraction ---\n",
        "# Simplified detection for dummy data: look for segments above amplitude threshold\n",
        "# and assume it corresponds to the 'fart' event.\n",
        "# In a real scenario, this would involve more sophisticated techniques.\n",
        "\n",
        "# Find indices where amplitude is above the threshold\n",
        "peak_indices = np.where(np.abs(audio) > amplitude_threshold)[0]\n",
        "\n",
        "fart_events = []\n",
        "if len(peak_indices) > 0:\n",
        "    # For simplicity with dummy_fart, assume one continuous event if any peaks detected\n",
        "    # In a real scenario, you'd group contiguous peak_indices into separate events\n",
        "    start_sample = peak_indices[0]\n",
        "    end_sample = peak_indices[-1]\n",
        "\n",
        "    # Extract segment for analysis\n",
        "    fart_segment = audio[start_sample:end_sample+1]\n",
        "\n",
        "    if len(fart_segment) > 0:\n",
        "        # Peak Amplitude for Velocity\n",
        "        peak_amplitude = np.max(np.abs(fart_segment))\n",
        "\n",
        "        # Duration\n",
        "        duration_seconds = len(fart_segment) / sr\n",
        "\n",
        "        # Dominant Frequency (simplified for a dummy low-freq burst)\n",
        "        # For real audio, you might use librosa.feature.spectral_centroid or similar\n",
        "        # Here, we can assume the frequency we generated it with, or a typical 'fart' frequency\n",
        "        dominant_frequency = 100 # Hz, based on dummy generation\n",
        "\n",
        "        fart_events.append({\n",
        "            \"start_time\": start_sample / sr,\n",
        "            \"duration\": duration_seconds,\n",
        "            \"peak_amplitude\": peak_amplitude,\n",
        "            \"dominant_frequency\": dominant_frequency\n",
        "        })\n",
        "        print(f\"✅ Detected 1 'fart-like' event. Amplitude: {peak_amplitude:.2f}, Duration: {duration_seconds:.2f}s\")\n",
        "else:\n",
        "    print(\"No 'fart-like' events detected above the amplitude threshold.\")\n",
        "\n",
        "# --- 4. MIDI Mapping and 5. MIDI File Generation --- #\n",
        "mid = MidiFile()\n",
        "track = MidiTrack()\n",
        "mid.tracks.append(track)\n",
        "\n",
        "ticks_per_beat = mid.ticks_per_beat # typically 480\n",
        "# Assuming 120 BPM for calculating ticks_per_second\n",
        "bpm = 120\n",
        "ticks_per_second = (ticks_per_beat * bpm) / 60\n",
        "\n",
        "for event in fart_events:\n",
        "    # Map Velocity\n",
        "    # Normalize peak_amplitude (e.g., max possible is 1.0 after librosa.load)\n",
        "    normalized_amplitude = min(event['peak_amplitude'] / 1.0, 1.0) # Clip to 1.0\n",
        "    midi_velocity = int(midi_velocity_min + (midi_velocity_max - midi_velocity_min) * normalized_amplitude)\n",
        "\n",
        "    # Map Pitch\n",
        "    # For simplicity, use a fixed low MIDI note, as exact pitch is hard for farts\n",
        "    # Could potentially map dominant_frequency to a pitch scale for more nuance\n",
        "    midi_note = midi_note_base # Assign a base low note\n",
        "\n",
        "    # Map Duration to MIDI ticks\n",
        "    midi_duration_ticks = int(event['duration'] * ticks_per_second)\n",
        "\n",
        "    print(f\"  - Mapping event to MIDI: Note={midi_note}, Velocity={midi_velocity}, Duration={midi_duration_ticks} ticks\")\n",
        "\n",
        "    # --- 6. Add MIDI Messages ---\n",
        "    track.append(Message('note_on', note=midi_note, velocity=midi_velocity, time=0)) # Time=0 for immediate note on\n",
        "    track.append(Message('note_off', note=midi_note, velocity=midi_velocity, time=midi_duration_ticks)) # Time is delta ticks\n",
        "\n",
        "# --- 7. Save MIDI File ---\n",
        "mid.save(MIDI_FILE)\n",
        "print(f\"✅ Generated MIDI file: {MIDI_FILE}\")\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Define a filename for the saved pipeline\n",
        "filename = 'trained_pipeline.joblib'\n",
        "\n",
        "# Save the trained pipeline to the file\n",
        "joblib.dump(pipeline, filename)\n",
        "\n",
        "print(f\"✅ Trained pipeline saved to {filename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f6863e6"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# Parameters for the new diverse dummy audio file\n",
        "sample_rate_diverse = 44100  # samples per second\n",
        "duration_diverse = 1.5        # seconds\n",
        "frequency_diverse = 150       # Hz (slightly varied frequency)\n",
        "\n",
        "# Generate time array\n",
        "t_diverse = np.linspace(0., duration_diverse, int(sample_rate_diverse * duration_diverse))\n",
        "\n",
        "# Generate a sine wave for the low frequency burst, with a slightly varied envelope\n",
        "amplitude_envelope_diverse = np.exp(-5 * t_diverse) * np.sin(2 * np.pi * 3 * t_diverse) + 0.1 # Varied envelope\n",
        "sound_wave_diverse = 0.6 * np.sin(2 * np.pi * frequency_diverse * t_diverse) * amplitude_envelope_diverse # Varied amplitude\n",
        "\n",
        "# Normalize to 16-bit integer range\n",
        "audio_data_diverse = (sound_wave_diverse * 32767).astype(np.int16)\n",
        "\n",
        "# Save the new dummy audio file\n",
        "file_name_diverse = \"dummy_fart_diverse.wav\"\n",
        "wavfile.write(file_name_diverse, sample_rate_diverse, audio_data_diverse)\n",
        "\n",
        "print(f\"✅ Generated diverse dummy audio file: {file_name_diverse}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb673c4b"
      },
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from mido import Message, MidiFile, MidiTrack\n",
        "import os\n",
        "\n",
        "# --- Configuration --- #\n",
        "AUDIO_FILE = \"dummy_fart_diverse.wav\" # Updated to diverse file\n",
        "MIDI_FILE = \"fart_midi_diverse.mid\" # Updated to diverse MIDI file\n",
        "SAMPLE_RATE = 44100 # Ensure this matches the dummy audio generation\n",
        "\n",
        "# 'Fart' detection parameters (can be tuned)\n",
        "amplitude_threshold = 0.1 # Adjust based on normalized audio\n",
        "low_freq_band_min = 20    # Hz\n",
        "low_freq_band_max = 200   # Hz\n",
        "\n",
        "# MIDI mapping parameters\n",
        "midi_note_base = 36 # C2 - a low MIDI note for farts\n",
        "midi_velocity_min = 60\n",
        "midi_velocity_max = 100\n",
        "\n",
        "# --- 1. Load Audio ---\n",
        "if not os.path.exists(AUDIO_FILE):\n",
        "    print(f\"Error: Audio file '{AUDIO_FILE}' not found. Please ensure it has been generated.\")\n",
        "    raise FileNotFoundError(f\"Audio file '{AUDIO_FILE}' is missing.\")\n",
        "\n",
        "audio, sr = librosa.load(AUDIO_FILE, sr=SAMPLE_RATE)\n",
        "print(f\"✅ Loaded audio file: {AUDIO_FILE} with sample rate {sr}\")\n",
        "\n",
        "# --- 2. Basic 'Fart' Detection and 3. Feature Extraction ---\n",
        "peak_indices = np.where(np.abs(audio) > amplitude_threshold)[0]\n",
        "\n",
        "fart_events = []\n",
        "if len(peak_indices) > 0:\n",
        "    # For simplicity with dummy_fart, assume one continuous event if any peaks detected\n",
        "    start_sample = peak_indices[0]\n",
        "    end_sample = peak_indices[-1]\n",
        "\n",
        "    fart_segment = audio[start_sample:end_sample+1]\n",
        "\n",
        "    if len(fart_segment) > 0:\n",
        "        peak_amplitude = np.max(np.abs(fart_segment))\n",
        "        duration_seconds = len(fart_segment) / sr\n",
        "        dominant_frequency = 150 # Hz, based on dummy_fart_diverse generation\n",
        "\n",
        "        fart_events.append({\n",
        "            \"start_time\": start_sample / sr,\n",
        "            \"duration\": duration_seconds,\n",
        "            \"peak_amplitude\": peak_amplitude,\n",
        "            \"dominant_frequency\": dominant_frequency\n",
        "        })\n",
        "        print(f\"✅ Detected 1 'fart-like' event. Amplitude: {peak_amplitude:.2f}, Duration: {duration_seconds:.2f}s\")\n",
        "else:\n",
        "    print(\"No 'fart-like' events detected above the amplitude threshold.\")\n",
        "\n",
        "# --- 4. MIDI Mapping and 5. MIDI File Generation --- #\n",
        "mid = MidiFile()\n",
        "track = MidiTrack()\n",
        "mid.tracks.append(track)\n",
        "\n",
        "ticks_per_beat = mid.ticks_per_beat\n",
        "bpm = 120\n",
        "ticks_per_second = (ticks_per_beat * bpm) / 60\n",
        "\n",
        "for event in fart_events:\n",
        "    normalized_amplitude = min(event['peak_amplitude'] / 1.0, 1.0)\n",
        "    midi_velocity = int(midi_velocity_min + (midi_velocity_max - midi_velocity_min) * normalized_amplitude)\n",
        "\n",
        "    midi_note = midi_note_base\n",
        "\n",
        "    midi_duration_ticks = int(event['duration'] * ticks_per_second)\n",
        "\n",
        "    print(f\"  - Mapping event to MIDI: Note={midi_note}, Velocity={midi_velocity}, Duration={midi_duration_ticks} ticks\")\n",
        "\n",
        "    # --- 6. Add MIDI Messages ---\n",
        "    track.append(Message('note_on', note=midi_note, velocity=midi_velocity, time=0))\n",
        "    track.append(Message('note_off', note=midi_note, velocity=midi_velocity, time=midi_duration_ticks))\n",
        "\n",
        "# --- 7. Save MIDI File ---\n",
        "mid.save(MIDI_FILE)\n",
        "print(f\"✅ Generated MIDI file: {MIDI_FILE}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96f1faf5"
      },
      "source": [
        "from mido import MidiFile\n",
        "\n",
        "# Load the newly generated MIDI file\n",
        "midi_file_to_verify = MidiFile(MIDI_FILE)\n",
        "\n",
        "print(f\"\\n--- Verifying MIDI file: {MIDI_FILE} ---\")\n",
        "for i, track in enumerate(midi_file_to_verify.tracks):\n",
        "    print(f'Track {i}: {track.name}')\n",
        "    for msg in track:\n",
        "        print(msg)\n",
        "print(\"--------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f5b8e67"
      },
      "source": [
        "print(f\"Current amplitude_threshold: {amplitude_threshold}\")\n",
        "print(f\"Current low_freq_band_min: {low_freq_band_min}\")\n",
        "print(f\"Current low_freq_band_max: {low_freq_band_max}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f65a0d0f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "# --- Visualize Audio Waveform --- #\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.waveshow(audio, sr=sr, alpha=0.6)\n",
        "plt.axhline(y=amplitude_threshold, color='r', linestyle='--', label=f'Amplitude Threshold ({amplitude_threshold:.2f})')\n",
        "plt.axhline(y=-amplitude_threshold, color='r', linestyle='--')\n",
        "plt.title('Audio Waveform of dummy_fart_diverse.wav with Amplitude Threshold')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- Visualize Spectrogram and Frequency Bands --- #\n",
        "plt.figure(figsize=(14, 5))\n",
        "D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
        "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.axhline(y=low_freq_band_min, color='g', linestyle='--', label=f'Low Freq Min ({low_freq_band_min} Hz)')\n",
        "plt.axhline(y=low_freq_band_max, color='b', linestyle='--', label=f'Low Freq Max ({low_freq_band_max} Hz)')\n",
        "plt.title('Spectrogram of dummy_fart_diverse.wav with Frequency Bands')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Frequency (Hz)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Visualized audio waveform and spectrogram with current detection parameters.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c3584a6"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous plot generated a UserWarning related to `loc=\"best\"` in `plt.legend()`. To avoid this warning and ensure consistent legend placement, I will explicitly set the `loc` parameter to 'upper right' for both plots.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a99ad40"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "# --- Visualize Audio Waveform --- #\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.waveshow(audio, sr=sr, alpha=0.6)\n",
        "plt.axhline(y=amplitude_threshold, color='r', linestyle='--', label=f'Amplitude Threshold ({amplitude_threshold:.2f})')\n",
        "plt.axhline(y=-amplitude_threshold, color='r', linestyle='--')\n",
        "plt.title('Audio Waveform of dummy_fart_diverse.wav with Amplitude Threshold')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend(loc='upper right') # Changed loc='best' to loc='upper right'\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- Visualize Spectrogram and Frequency Bands --- #\n",
        "plt.figure(figsize=(14, 5))\n",
        "D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
        "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.axhline(y=low_freq_band_min, color='g', linestyle='--', label=f'Low Freq Min ({low_freq_band_min} Hz)')\n",
        "plt.axhline(y=low_freq_band_max, color='b', linestyle='--', label=f'Low Freq Max ({low_freq_band_max} Hz)')\n",
        "plt.title('Spectrogram of dummy_fart_diverse.wav with Frequency Bands')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Frequency (Hz)')\n",
        "plt.legend(loc='upper right') # Changed loc='best' to loc='upper right'\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Visualized audio waveform and spectrogram with current detection parameters.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb04ea5d"
      },
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from mido import Message, MidiFile, MidiTrack\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "AUDIO_FILE = \"dummy_fart_diverse.wav\" # Updated to diverse file\n",
        "MIDI_FILE = \"fart_midi_diverse.mid\" # Updated to diverse MIDI file\n",
        "SAMPLE_RATE = 44100 # Ensure this matches the dummy audio generation\n",
        "\n",
        "# 'Fart' detection parameters (can be tuned)\n",
        "amplitude_threshold = 0.15 # Adjusted from 0.1 to 0.15\n",
        "low_freq_band_min = 120    # Adjusted from 20 to 120 Hz\n",
        "low_freq_band_max = 180   # Adjusted from 200 to 180 Hz\n",
        "\n",
        "# MIDI mapping parameters\n",
        "midi_note_base = 36 # C2 - a low MIDI note for farts\n",
        "midi_velocity_min = 60\n",
        "midi_velocity_max = 100\n",
        "\n",
        "# --- 1. Load Audio ---\n",
        "if not os.path.exists(AUDIO_FILE):\n",
        "    print(f\"Error: Audio file '{AUDIO_FILE}' not found. Please ensure it has been generated.\")\n",
        "    raise FileNotFoundError(f\"Audio file '{AUDIO_FILE}' is missing.\")\n",
        "\n",
        "audio, sr = librosa.load(AUDIO_FILE, sr=SAMPLE_RATE)\n",
        "print(f\"✅ Loaded audio file: {AUDIO_FILE} with sample rate {sr}\")\n",
        "\n",
        "# --- 2. Basic 'Fart' Detection and 3. Feature Extraction ---\n",
        "peak_indices = np.where(np.abs(audio) > amplitude_threshold)[0]\n",
        "\n",
        "fart_events = []\n",
        "if len(peak_indices) > 0:\n",
        "    # For simplicity with dummy_fart, assume one continuous event if any peaks detected\n",
        "    start_sample = peak_indices[0]\n",
        "    end_sample = peak_indices[-1]\n",
        "\n",
        "    fart_segment = audio[start_sample:end_sample+1]\n",
        "\n",
        "    if len(fart_segment) > 0:\n",
        "        peak_amplitude = np.max(np.abs(fart_segment))\n",
        "        duration_seconds = len(fart_segment) / sr\n",
        "        dominant_frequency = 150 # Hz, based on dummy_fart_diverse generation\n",
        "\n",
        "        fart_events.append({\n",
        "            \"start_time\": start_sample / sr,\n",
        "            \"duration\": duration_seconds,\n",
        "            \"peak_amplitude\": peak_amplitude,\n",
        "            \"dominant_frequency\": dominant_frequency\n",
        "        })\n",
        "        print(f\"✅ Detected 1 'fart-like' event. Amplitude: {peak_amplitude:.2f}, Duration: {duration_seconds:.2f}s\")\n",
        "else:\n",
        "    print(\"No 'fart-like' events detected above the amplitude threshold.\")\n",
        "\n",
        "# --- 4. MIDI Mapping and 5. MIDI File Generation --- #\n",
        "mid = MidiFile()\n",
        "track = MidiTrack()\n",
        "mid.tracks.append(track)\n",
        "\n",
        "ticks_per_beat = mid.ticks_per_beat\n",
        "bpm = 120\n",
        "ticks_per_second = (ticks_per_beat * bpm) / 60\n",
        "\n",
        "for event in fart_events:\n",
        "    normalized_amplitude = min(event['peak_amplitude'] / 1.0, 1.0)\n",
        "    midi_velocity = int(midi_velocity_min + (midi_velocity_max - midi_velocity_min) * normalized_amplitude)\n",
        "\n",
        "    midi_note = midi_note_base\n",
        "\n",
        "    midi_duration_ticks = int(event['duration'] * ticks_per_second)\n",
        "\n",
        "    print(f\"  - Mapping event to MIDI: Note={midi_note}, Velocity={midi_velocity}, Duration={midi_duration_ticks} ticks\")\n",
        "\n",
        "    # --- 6. Add MIDI Messages ---\n",
        "    track.append(Message('note_on', note=midi_note, velocity=midi_velocity, time=0))\n",
        "    track.append(Message('note_off', note=midi_note, velocity=midi_velocity, time=midi_duration_ticks))\n",
        "\n",
        "# --- 7. Save MIDI File ---\n",
        "mid.save(MIDI_FILE)\n",
        "print(f\"✅ Generated MIDI file: {MIDI_FILE}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cf40d92"
      },
      "source": [
        "print(f\"Current amplitude_threshold: {amplitude_threshold}\")\n",
        "print(f\"Current low_freq_band_min: {low_freq_band_min}\")\n",
        "print(f\"Current low_freq_band_max: {low_freq_band_max}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0ed4240"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "# --- Visualize Audio Waveform --- #\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.waveshow(audio, sr=sr, alpha=0.6)\n",
        "plt.axhline(y=amplitude_threshold, color='r', linestyle='--', label=f'Amplitude Threshold ({amplitude_threshold:.2f})')\n",
        "plt.axhline(y=-amplitude_threshold, color='r', linestyle='--')\n",
        "plt.title('Audio Waveform of dummy_fart_diverse.wav with Adjusted Amplitude Threshold')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- Visualize Spectrogram and Frequency Bands --- #\n",
        "plt.figure(figsize=(14, 5))\n",
        "D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
        "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.axhline(y=low_freq_band_min, color='g', linestyle='--', label=f'Low Freq Min ({low_freq_band_min} Hz)')\n",
        "plt.axhline(y=low_freq_band_max, color='b', linestyle='--', label=f'Low Freq Max ({low_freq_band_max} Hz)')\n",
        "plt.title('Spectrogram of dummy_fart_diverse.wav with Adjusted Frequency Bands')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Frequency (Hz)')\n",
        "plt.legend(loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Visualized audio waveform and spectrogram with adjusted detection parameters.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "598b6d6c"
      },
      "source": [
        "**Reasoning**:\n",
        "I will print the `fart_events` list to observe the detailed characteristics (start time, duration, peak amplitude, dominant frequency) of the detected event(s) with the adjusted parameters, as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78f89034"
      },
      "source": [
        "print(f\"Detected Fart Events with adjusted parameters: {fart_events}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71dbf9ff"
      },
      "source": [
        "from mido import MidiFile\n",
        "\n",
        "# Load the newly generated MIDI file\n",
        "midi_file_to_verify = MidiFile(MIDI_FILE)\n",
        "\n",
        "print(f\"\\n--- Verifying MIDI file: {MIDI_FILE} with adjusted parameters ---\")\n",
        "for i, track in enumerate(midi_file_to_verify.tracks):\n",
        "    print(f'Track {i}: {track.name}')\n",
        "    for msg in track:\n",
        "        print(msg)\n",
        "print(\"--------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87220aaa"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 2. Define a base Python class, MLModelStub\n",
        "class MLModelStub:\n",
        "    \"\"\"Base class for ML model stubs.\"\"\"\n",
        "    def __init__(self, model_name=\"MLModel\"):\n",
        "        self.model_name = model_name\n",
        "        print(f\"Initialized placeholder for {self.model_name}.\")\n",
        "\n",
        "    # 3. Implement the predict method within MLModelStub to raise a NotImplementedError\n",
        "    def predict(self, features: np.ndarray):\n",
        "        \"\"\"Placeholder predict method. Should be overridden by subclasses.\"\"\"\n",
        "        raise NotImplementedError(\"Predict method must be implemented by subclasses.\")\n",
        "\n",
        "# 4. Create four separate Python classes: XGBoostStub, SVMStub, RandomForestStub, and CARTStub.\n",
        "# 5. For each specific stub class, override the predict method to return a placeholder prediction.\n",
        "# 6. Add comments within each stub class.\n",
        "\n",
        "class XGBoostStub(MLModelStub):\n",
        "    \"\"\"Placeholder for an XGBoost model. In a real scenario, this would be a trained XGBoost model.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(\"XGBoost Model\")\n",
        "\n",
        "    def predict(self, features: np.ndarray):\n",
        "        # Example: return a simple mean of the features to simulate a regression prediction\n",
        "        return np.mean(features) + 0.1 # Small offset for variety\n",
        "\n",
        "class SVMStub(MLModelStub):\n",
        "    \"\"\"Placeholder for an SVM model. In a real scenario, this would be a trained SVM model.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(\"SVM Model\")\n",
        "\n",
        "    def predict(self, features: np.ndarray):\n",
        "        # Example: return a classification-like output based on the sum of features\n",
        "        return \"class_A\" if np.sum(features) > 1.0 else \"class_B\"\n",
        "\n",
        "class RandomForestStub(MLModelStub):\n",
        "    \"\"\"Placeholder for a RandomForest model. In a real scenario, this would be a trained RandomForest model.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(\"RandomForest Model\")\n",
        "\n",
        "    def predict(self, features: np.ndarray):\n",
        "        # Example: return a value based on the maximum feature to simulate a prediction\n",
        "        return np.max(features) * 2.5\n",
        "\n",
        "class CARTStub(MLModelStub):\n",
        "    \"\"\"Placeholder for a CART (Decision Tree) model. In a real scenario, this would be a trained CART model.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(\"CART Model\")\n",
        "\n",
        "    def predict(self, features: np.ndarray):\n",
        "        # Example: return a boolean based on a simple threshold of the first feature\n",
        "        return features[0, 0] > 0.7 # Assumes features is 2D array and checks first element\n",
        "\n",
        "print(\"\\n--- Instantiating and Testing Stub Models ---\")\n",
        "\n",
        "# 7. Instantiate an object for each of the four stub models\n",
        "xgb_stub = XGBoostStub()\n",
        "svm_stub = SVMStub()\n",
        "rf_stub = RandomForestStub()\n",
        "cart_stub = CARTStub()\n",
        "\n",
        "# 8. Create a sample input feature array\n",
        "sample_input = np.array([[0.5, 0.2, 0.8]])\n",
        "print(f\"\\nSample input features: {sample_input}\")\n",
        "\n",
        "# 9. Call the predict method for each instantiated stub model and print the results\n",
        "print(f\"XGBoost Prediction: {xgb_stub.predict(sample_input)}\")\n",
        "print(f\"SVM Prediction: {svm_stub.predict(sample_input)}\")\n",
        "print(f\"RandomForest Prediction: {rf_stub.predict(sample_input)}\")\n",
        "print(f\"CART Prediction: {cart_stub.predict(sample_input)}\")\n",
        "\n",
        "print(\"\\n✅ Successfully created and tested placeholder ML model stubs.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c17e030b"
      },
      "source": [
        "import numpy as np\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "# Assuming MLModelStub and its subclasses (XGBoostStub, SVMStub, RandomForestStub, CARTStub)\n",
        "# are defined in a previous cell. If not, they would need to be included here.\n",
        "# For the purpose of this cell, we will assume they are in scope.\n",
        "\n",
        "# --- 1. Define CartmanLLMRoaster Stub ---\n",
        "class CartmanLLMRoaster:\n",
        "    \"\"\"Placeholder for the Cartman-style LLM roast generator.\"\"\"\n",
        "    def __init__(self):\n",
        "        print(\"Initialized placeholder for CartmanLLMRoaster.\")\n",
        "\n",
        "    def generate_roast(self, fart_characteristics: Dict[str, Any]) -> str:\n",
        "        \"\"\"Generates a mock roast based on fart characteristics.\"\"\"\n",
        "        roast_template = \"Oh, that was a {type}, {intensity}, {duration} fart with a hint of {smell}. You need to work on your technique, fatty!\"\n",
        "\n",
        "        # Default values if characteristics are not provided or are generic\n",
        "        fart_type = fart_characteristics.get('type', 'generic')\n",
        "        intensity = fart_characteristics.get('intensity', 'mild')\n",
        "        duration = fart_characteristics.get('duration', 'brief')\n",
        "        smell = fart_characteristics.get('smell', 'unidentifiable')\n",
        "\n",
        "        # Simple mapping for more interesting roasts based on stub outputs\n",
        "        if fart_characteristics.get('svm_prediction') == 'class_A':\n",
        "            intensity = 'thunderous'\n",
        "        elif fart_characteristics.get('svm_prediction') == 'class_B':\n",
        "            intensity = 'whisper-soft'\n",
        "\n",
        "        if fart_characteristics.get('xgboost_prediction', 0) > 0.5:\n",
        "            duration = 'lingering'\n",
        "        elif fart_characteristics.get('xgboost_prediction', 0) <= 0.5:\n",
        "            duration = 'quick burst'\n",
        "\n",
        "        if fart_characteristics.get('random_forest_prediction', 0) > 1.5:\n",
        "            fart_type = 'gassy explosion'\n",
        "        else:\n",
        "            fart_type = 'modest puff'\n",
        "\n",
        "        if fart_characteristics.get('cart_prediction') is True:\n",
        "            smell = 'sulfur and regret'\n",
        "        else:\n",
        "            smell = 'fresh mountain air (not!)'\n",
        "\n",
        "        return roast_template.format(\n",
        "            type=fart_type,\n",
        "            intensity=intensity,\n",
        "            duration=duration,\n",
        "            smell=smell\n",
        "        )\n",
        "\n",
        "# --- 2. Create the FartRoastPipeline class ---\n",
        "class FartRoastPipeline:\n",
        "    \"\"\"A Hugging Face-like pipeline for detecting farts, classifying them with ML, and roasting them with an LLM.\"\"\"\n",
        "    def __init__(self, traditional_models: Dict[str, Any], llm_roaster: CartmanLLMRoaster):\n",
        "        self.traditional_models = traditional_models\n",
        "        self.llm_roaster = llm_roaster\n",
        "        print(\"Initialized FartRoastPipeline with ML models and LLM roaster.\")\n",
        "\n",
        "    def __call__(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        return self.generate_roast(audio_features)\n",
        "\n",
        "    def generate_roast(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"Orchestrates the ML predictions and LLM roast generation.\"\"\"\n",
        "        print(f\"\\nProcessing audio features: {audio_features}\")\n",
        "        fart_characteristics = {}\n",
        "        ml_predictions = {}\n",
        "\n",
        "        # a. Call predict method of each traditional ML model stub\n",
        "        for model_name, model_stub in self.traditional_models.items():\n",
        "            prediction = model_stub.predict(audio_features)\n",
        "            ml_predictions[f'{model_name}_prediction'] = prediction\n",
        "            print(f\"  - {model_name} prediction: {prediction}\")\n",
        "\n",
        "        # b. Aggregate predictions into fart_characteristics for LLM\n",
        "        # and c. Construct dictionary for CartmanLLMRoaster\n",
        "        # This mapping is simplified for stub demonstration\n",
        "        fart_characteristics = {\n",
        "            'xgboost_prediction': ml_predictions.get('XGBoost Model_prediction'),\n",
        "            'svm_prediction': ml_predictions.get('SVM Model_prediction'),\n",
        "            'random_forest_prediction': ml_predictions.get('RandomForest Model_prediction'),\n",
        "            'cart_prediction': ml_predictions.get('CART Model_prediction')\n",
        "        }\n",
        "\n",
        "        # d. Call the generate_roast method of the CartmanLLMRoaster instance\n",
        "        roast_text = self.llm_roaster.generate_roast(fart_characteristics)\n",
        "        print(f\"  - LLM generated roast.\")\n",
        "\n",
        "        # e. Return results\n",
        "        return {\n",
        "            \"roast_text\": roast_text,\n",
        "            \"ml_predictions\": ml_predictions\n",
        "        }\n",
        "\n",
        "print(\"\\n--- Instantiating all stubs ---\")\n",
        "# Instantiate the previously defined stub models\n",
        "xgb_stub = XGBoostStub()\n",
        "svm_stub = SVMStub()\n",
        "rf_stub = RandomForestStub()\n",
        "cart_stub = CARTStub()\n",
        "\n",
        "# Instantiate the new CartmanLLMRoaster\n",
        "cartman_llm = CartmanLLMRoaster()\n",
        "\n",
        "print(\"\\n--- Creating FartRoastPipeline instance ---\")\n",
        "pipeline_models = {\n",
        "    \"XGBoost Model\": xgb_stub,\n",
        "    \"SVM Model\": svm_stub,\n",
        "    \"RandomForest Model\": rf_stub,\n",
        "    \"CART Model\": cart_stub\n",
        "}\n",
        "fart_roast_pipeline = FartRoastPipeline(traditional_models=pipeline_models, llm_roaster=cartman_llm)\n",
        "\n",
        "# --- Prepare sample audio features ---\n",
        "sample_audio_features = np.array([[0.6, 0.3, 0.9]]) # Slightly different from previous sample_input\n",
        "print(f\"\\nSample audio features for pipeline: {sample_audio_features}\")\n",
        "\n",
        "# --- Call the FartRoastPipeline instance and print the result ---\n",
        "print(\"\\n--- Running the FartRoastPipeline ---\")\n",
        "result = fart_roast_pipeline(sample_audio_features)\n",
        "\n",
        "print(\"\\n--- Pipeline Result ---\")\n",
        "print(f\"Roast: {result['roast_text']}\")\n",
        "print(f\"ML Predictions: {result['ml_predictions']}\")\n",
        "\n",
        "print(\"\\n✅ Successfully designed and demonstrated the FartRoastPipeline.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "ES2jO5VeBJLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.model_download('deepseek-ai/deepseek-r1/transformers/deepseek-r1-distill-qwen-1.5b/2')"
      ],
      "metadata": {
        "id": "COJIenNhCX8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(path)\n",
        "model = AutoModelForCausalLM.from_pretrained(path)\n",
        "\n",
        "inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs)\n",
        "print(tokenizer.decode(outputs[0]))\n"
      ],
      "metadata": {
        "id": "4t5kJ2tZC84X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2933e840"
      },
      "source": [
        "import numpy as np\n",
        "from typing import Dict, Any, List\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- Access Google API Key securely ---\n",
        "# Make sure to set up GOOGLE_API_KEY in Colab secrets as per instructions.\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "if GOOGLE_API_KEY is not None:\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"✅ Google Generative AI configured successfully.\")\n",
        "else:\n",
        "    print(\"❌ GOOGLE_API_KEY not found in Colab secrets. Please set it up to proceed.\")\n",
        "    # Exit or raise error if API key is critical for further steps\n",
        "\n",
        "# Assuming MLModelStub and its subclasses are defined in a previous cell.\n",
        "# If not, they would need to be included here.\n",
        "\n",
        "# --- 1. Define CartmanLLMRoaster Stub (now with Gemini integration) ---\n",
        "class CartmanLLMRoaster:\n",
        "    \"\"\"Integrates with Google Gemini API to generate Cartman-style roasts.\"\"\"\n",
        "    def __init__(self):\n",
        "        if GOOGLE_API_KEY is None:\n",
        "            raise ValueError(\"Google API Key is not configured. Cannot initialize Gemini model.\")\n",
        "        self.model = genai.GenerativeModel('gemini-pro')\n",
        "        print(\"Initialized CartmanLLMRoaster with Gemini Model.\")\n",
        "\n",
        "    def generate_roast(self, fart_characteristics: Dict[str, Any]) -> str:\n",
        "        \"\"\"Generates a roast using the Gemini model based on fart characteristics.\"\"\"\n",
        "        # Construct a dynamic prompt for Gemini\n",
        "        fart_type = fart_characteristics.get('type', 'generic')\n",
        "        intensity = fart_characteristics.get('intensity', 'mild')\n",
        "        duration = fart_characteristics.get('duration', 'brief')\n",
        "        smell = fart_characteristics.get('smell', 'unidentifiable')\n",
        "\n",
        "        # Use ML predictions to make the roast more specific and dynamic\n",
        "        if fart_characteristics.get('svm_prediction') == 'class_A':\n",
        "            intensity = 'thunderous'\n",
        "        elif fart_characteristics.get('svm_prediction') == 'class_B':\n",
        "            intensity = 'whisper-soft'\n",
        "\n",
        "        if fart_characteristics.get('xgboost_prediction', 0) > 0.5:\n",
        "            duration = 'lingering'\n",
        "        elif fart_characteristics.get('xgboost_prediction', 0) <= 0.5:\n",
        "            duration = 'quick burst'\n",
        "\n",
        "        if fart_characteristics.get('random_forest_prediction', 0) > 1.5:\n",
        "            fart_type = 'gassy explosion'\n",
        "        else:\n",
        "            fart_type = 'modest puff'\n",
        "\n",
        "        if fart_characteristics.get('cart_prediction') is True:\n",
        "            smell = 'sulfur and regret'\n",
        "        else:\n",
        "            smell = 'fresh mountain air (not!)'\n",
        "\n",
        "        prompt_text = (\n",
        "            f\"You are Eric Cartman from South Park. Generate a short, insulting roast \"\n",
        "            f\"about a fart with the following characteristics: \"\n",
        "            f\"Type: {fart_type}, Intensity: {intensity}, Duration: {duration}, Smell: {smell}. \"\n",
        "            f\"Make it in your typical Cartman style, use some exaggeration and sarcasm, and make it sound like you're personally offended. \"\n",
        "            f\"Keep it concise, under 50 words.\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt_text)\n",
        "            # Extract and return the generated roast text\n",
        "            roast_text = response.text\n",
        "        except Exception as e:\n",
        "            roast_text = f\"Failed to generate roast with Gemini: {e}. Defaulting to fixed roast. \"\n",
        "            roast_text += f\"Oh, that was a {fart_type}, {intensity}, {duration} fart with a hint of {smell}. You need to work on your technique, fatty!\"\n",
        "\n",
        "        return roast_text\n",
        "\n",
        "# --- 2. Create the FartRoastPipeline class (copied for re-definition) ---\n",
        "class FartRoastPipeline:\n",
        "    \"\"\"A Hugging Face-like pipeline for detecting farts, classifying them with ML, and roasting them with an LLM.\"\"\"\n",
        "    def __init__(self, traditional_models: Dict[str, Any], llm_roaster: CartmanLLMRoaster):\n",
        "        self.traditional_models = traditional_models\n",
        "        self.llm_roaster = llm_roaster\n",
        "        print(\"Initialized FartRoastPipeline with ML models and LLM roaster.\")\n",
        "\n",
        "    def __call__(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        return self.generate_roast(audio_features)\n",
        "\n",
        "    def generate_roast(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"Orchestrates the ML predictions and LLM roast generation.\"\"\"\n",
        "        print(f\"\\nProcessing audio features: {audio_features}\")\n",
        "        fart_characteristics = {}\n",
        "        ml_predictions = {}\n",
        "\n",
        "        # a. Call predict method of each traditional ML model stub\n",
        "        for model_name, model_stub in self.traditional_models.items():\n",
        "            prediction = model_stub.predict(audio_features)\n",
        "            ml_predictions[f'{model_name}_prediction'] = prediction\n",
        "            print(f\"  - {model_name} prediction: {prediction}\")\n",
        "\n",
        "        # b. Aggregate predictions into fart_characteristics for LLM\n",
        "        # and c. Construct dictionary for CartmanLLMRoaster\n",
        "        fart_characteristics = {\n",
        "            'xgboost_prediction': ml_predictions.get('XGBoost Model_prediction'),\n",
        "            'svm_prediction': ml_predictions.get('SVM Model_prediction'),\n",
        "            'random_forest_prediction': ml_predictions.get('RandomForest Model_prediction'),\n",
        "            'cart_prediction': ml_predictions.get('CART Model_prediction')\n",
        "        }\n",
        "\n",
        "        # d. Call the generate_roast method of the CartmanLLMRoaster instance\n",
        "        roast_text = self.llm_roaster.generate_roast(fart_characteristics)\n",
        "        print(f\"  - LLM generated roast.\")\n",
        "\n",
        "        # e. Return results\n",
        "        return {\n",
        "            \"roast_text\": roast_text,\n",
        "            \"ml_predictions\": ml_predictions\n",
        "        }\n",
        "\n",
        "print(\"\\n--- Re-Instantiating all stubs ---\")\n",
        "# Instantiate the previously defined stub models (assuming they are in scope)\n",
        "# If not, the MLModelStub and its subclasses need to be defined here again or imported.\n",
        "\n",
        "# For this demonstration, we'll re-define them minimally if they aren't in scope\n",
        "# or assume they are still defined from previous successful execution.\n",
        "\n",
        "# Placeholder classes for demonstration if previous cells are not executed in order\n",
        "class MLModelStub:\n",
        "    def __init__(self, model_name=\"MLModel\"): self.model_name = model_name\n",
        "    def predict(self, features: np.ndarray): raise NotImplementedError(\"Predict method must be implemented by subclasses.\")\n",
        "\n",
        "class XGBoostStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"XGBoost Model\")\n",
        "    def predict(self, features: np.ndarray): return np.mean(features) + 0.1\n",
        "\n",
        "class SVMStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"SVM Model\")\n",
        "    def predict(self, features: np.ndarray): return \"class_A\" if np.sum(features) > 1.0 else \"class_B\"\n",
        "\n",
        "class RandomForestStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"RandomForest Model\")\n",
        "    def predict(self, features: np.ndarray): return np.max(features) * 2.5\n",
        "\n",
        "class CARTStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"CART Model\")\n",
        "    def predict(self, features: np.ndarray): return features[0, 0] > 0.7\n",
        "\n",
        "\n",
        "xgb_stub = XGBoostStub()\n",
        "svm_stub = SVMStub()\n",
        "rf_stub = RandomForestStub()\n",
        "cart_stub = CARTStub()\n",
        "\n",
        "# Instantiate the new CartmanLLMRoaster\n",
        "cartman_llm = CartmanLLMRoaster()\n",
        "\n",
        "print(\"\\n--- Re-Creating FartRoastPipeline instance ---\")\n",
        "pipeline_models = {\n",
        "    \"XGBoost Model\": xgb_stub,\n",
        "    \"SVM Model\": svm_stub,\n",
        "    \"RandomForest Model\": rf_stub,\n",
        "    \"CART Model\": cart_stub\n",
        "}\n",
        "fart_roast_pipeline = FartRoastPipeline(traditional_models=pipeline_models, llm_roaster=cartman_llm)\n",
        "\n",
        "# --- Prepare sample audio features ---\n",
        "sample_audio_features = np.array([[0.6, 0.3, 0.9]]) # Slightly different from previous sample_input\n",
        "print(f\"\\nSample audio features for pipeline: {sample_audio_features}\")\n",
        "\n",
        "# --- Call the FartRoastPipeline instance and print the result ---\n",
        "print(\"\\n--- Running the FartRoastPipeline ---\")\n",
        "result = fart_roast_pipeline(sample_audio_features)\n",
        "\n",
        "print(\"\\n--- Pipeline Result ---\")\n",
        "print(f\"Roast: {result['roast_text']}\")\n",
        "print(f\"ML Predictions: {result['ml_predictions']}\")\n",
        "\n",
        "print(\"\\n✅ Successfully upgraded CartmanLLMRoaster with Gemini API and demonstrated the FartRoastPipeline.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fe7d6f8"
      },
      "source": [
        "import numpy as np\n",
        "from typing import Dict, Any, List\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- Access Google API Key securely ---\n",
        "# Make sure to set up GOOGLE_API_KEY in Colab secrets as per instructions.\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "if GOOGLE_API_KEY is not None:\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"✅ Google Generative AI configured successfully.\")\n",
        "else:\n",
        "    print(\"❌ GOOGLE_API_KEY not found in Colab secrets. Please set it up to proceed.\")\n",
        "    # Exit or raise error if API key is critical for further steps\n",
        "\n",
        "# Assuming MLModelStub and its subclasses are defined in a previous cell.\n",
        "# If not, they would need to be included here.\n",
        "\n",
        "# --- 1. Define CartmanLLMRoaster Stub (now with Gemini integration) ---\n",
        "class CartmanLLMRoaster:\n",
        "    \"\"\"Integrates with Google Gemini API to generate Cartman-style roasts.\"\"\"\n",
        "    def __init__(self):\n",
        "        if GOOGLE_API_KEY is None:\n",
        "            raise ValueError(\"Google API Key is not configured. Cannot initialize Gemini model.\")\n",
        "        self.model = genai.GenerativeModel('gemini-pro')\n",
        "        print(\"Initialized CartmanLLMRoaster with Gemini Model.\")\n",
        "\n",
        "    def generate_roast(self, fart_characteristics: Dict[str, Any]) -> str:\n",
        "        \"\"\"Generates a roast using the Gemini model based on fart characteristics.\"\"\"\n",
        "        # Construct a dynamic prompt for Gemini\n",
        "        fart_type = fart_characteristics.get('type', 'generic')\n",
        "        intensity = fart_characteristics.get('intensity', 'mild')\n",
        "        duration = fart_characteristics.get('duration', 'brief')\n",
        "        smell = fart_characteristics.get('smell', 'unidentifiable')\n",
        "\n",
        "        # Use ML predictions to make the roast more specific and dynamic\n",
        "        if fart_characteristics.get('svm_prediction') == 'class_A':\n",
        "            intensity = 'thunderous'\n",
        "        elif fart_characteristics.get('svm_prediction') == 'class_B':\n",
        "            intensity = 'whisper-soft'\n",
        "\n",
        "        if fart_characteristics.get('xgboost_prediction', 0) > 0.5:\n",
        "            duration = 'lingering'\n",
        "        elif fart_characteristics.get('xgboost_prediction', 0) <= 0.5:\n",
        "            duration = 'quick burst'\n",
        "\n",
        "        if fart_characteristics.get('random_forest_prediction', 0) > 1.5:\n",
        "            fart_type = 'gassy explosion'\n",
        "        else:\n",
        "            fart_type = 'modest puff'\n",
        "\n",
        "        if fart_characteristics.get('cart_prediction') is True:\n",
        "            smell = 'sulfur and regret'\n",
        "        else:\n",
        "            smell = 'fresh mountain air (not!)'\n",
        "\n",
        "        prompt_text = (\n",
        "            f\"You are Eric Cartman from South Park. Generate a short, insulting roast \"\n",
        "            f\"about a fart with the following characteristics: \"\n",
        "            f\"Type: {fart_type}, Intensity: {intensity}, Duration: {duration}, Smell: {smell}. \"\n",
        "            f\"Make it in your typical Cartman style, use some exaggeration and sarcasm, and make it sound like you're personally offended. \"\n",
        "            f\"Keep it concise, under 50 words.\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt_text)\n",
        "            # Extract and return the generated roast text\n",
        "            roast_text = response.text\n",
        "        except Exception as e:\n",
        "            roast_text = f\"Failed to generate roast with Gemini: {e}. Defaulting to fixed roast. \"\n",
        "            roast_text += f\"Oh, that was a {fart_type}, {intensity}, {duration} fart with a hint of {smell}. You need to work on your technique, fatty!\"\n",
        "\n",
        "        return roast_text\n",
        "\n",
        "# --- 2. Create the FartRoastPipeline class (copied for re-definition) ---\n",
        "class FartRoastPipeline:\n",
        "    \"\"\"A Hugging Face-like pipeline for detecting farts, classifying them with ML, and roasting them with an LLM.\"\"\"\n",
        "    def __init__(self, traditional_models: Dict[str, Any], llm_roaster: CartmanLLMRoaster):\n",
        "        self.traditional_models = traditional_models\n",
        "        self.llm_roaster = llm_roaster\n",
        "        print(\"Initialized FartRoastPipeline with ML models and LLM roaster.\")\n",
        "\n",
        "    def __call__(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        return self.generate_roast(audio_features)\n",
        "\n",
        "    def generate_roast(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"Orchestrates the ML predictions and LLM roast generation.\"\"\"\n",
        "        print(f\"\\nProcessing audio features: {audio_features}\")\n",
        "        fart_characteristics = {}\n",
        "        ml_predictions = {}\n",
        "\n",
        "        # a. Call predict method of each traditional ML model stub\n",
        "        for model_name, model_stub in self.traditional_models.items():\n",
        "            prediction = model_stub.predict(audio_features)\n",
        "            ml_predictions[f'{model_name}_prediction'] = prediction\n",
        "            print(f\"  - {model_name} prediction: {prediction}\")\n",
        "\n",
        "        # b. Aggregate predictions into fart_characteristics for LLM\n",
        "        # and c. Construct dictionary for CartmanLLMRoaster\n",
        "        fart_characteristics = {\n",
        "            'xgboost_prediction': ml_predictions.get('XGBoost Model_prediction'),\n",
        "            'svm_prediction': ml_predictions.get('SVM Model_prediction'),\n",
        "            'random_forest_prediction': ml_predictions.get('RandomForest Model_prediction'),\n",
        "            'cart_prediction': ml_predictions.get('CART Model_prediction')\n",
        "        }\n",
        "\n",
        "        # d. Call the generate_roast method of the CartmanLLMRoaster instance\n",
        "        roast_text = self.llm_roaster.generate_roast(fart_characteristics)\n",
        "        print(f\"  - LLM generated roast.\")\n",
        "\n",
        "        # e. Return results\n",
        "        return {\n",
        "            \"roast_text\": roast_text,\n",
        "            \"ml_predictions\": ml_predictions\n",
        "        }\n",
        "\n",
        "print(\"\\n--- Re-Instantiating all stubs ---\")\n",
        "# Instantiate the previously defined stub models (assuming they are in scope)\n",
        "# If not, the MLModelStub and its subclasses need to be defined here again or imported.\n",
        "\n",
        "# For this demonstration, we'll re-define them minimally if they aren't in scope\n",
        "# or assume they are still defined from previous successful execution.\n",
        "\n",
        "# Placeholder classes for demonstration if previous cells are not executed in order\n",
        "class MLModelStub:\n",
        "    def __init__(self, model_name=\"MLModel\"): self.model_name = model_name\n",
        "    def predict(self, features: np.ndarray): raise NotImplementedError(\"Predict method must be implemented by subclasses.\")\n",
        "\n",
        "class XGBoostStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"XGBoost Model\")\n",
        "    def predict(self, features: np.ndarray): return np.mean(features) + 0.1\n",
        "\n",
        "class SVMStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"SVM Model\")\n",
        "    def predict(self, features: np.ndarray): return \"class_A\" if np.sum(features) > 1.0 else \"class_B\"\n",
        "\n",
        "class RandomForestStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"RandomForest Model\")\n",
        "    def predict(self, features: np.ndarray): return np.max(features) * 2.5\n",
        "\n",
        "class CARTStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"CART Model\")\n",
        "    def predict(self, features: np.ndarray): return features[0, 0] > 0.7\n",
        "\n",
        "\n",
        "xgb_stub = XGBoostStub()\n",
        "svm_stub = SVMStub()\n",
        "rf_stub = RandomForestStub()\n",
        "cart_stub = CARTStub()\n",
        "\n",
        "# Instantiate the new CartmanLLMRoaster\n",
        "cartman_llm = CartmanLLMRoaster()\n",
        "\n",
        "print(\"\\n--- Re-Creating FartRoastPipeline instance ---\")\n",
        "pipeline_models = {\n",
        "    \"XGBoost Model\": xgb_stub,\n",
        "    \"SVM Model\": svm_stub,\n",
        "    \"RandomForest Model\": rf_stub,\n",
        "    \"CART Model\": cart_stub\n",
        "}\n",
        "fart_roast_pipeline = FartRoastPipeline(traditional_models=pipeline_models, llm_roaster=cartman_llm)\n",
        "\n",
        "# --- Prepare sample audio features ---\n",
        "sample_audio_features = np.array([[0.6, 0.3, 0.9]]) # Slightly different from previous sample_input\n",
        "print(f\"\\nSample audio features for pipeline: {sample_audio_features}\")\n",
        "\n",
        "# --- Call the FartRoastPipeline instance and print the result ---\n",
        "print(\"\\n--- Running the FartRoastPipeline ---\")\n",
        "result = fart_roast_pipeline(sample_audio_features)\n",
        "\n",
        "print(\"\\n--- Pipeline Result ---\")\n",
        "print(f\"Roast: {result['roast_text']}\")\n",
        "print(f\"ML Predictions: {result['ml_predictions']}\")\n",
        "\n",
        "print(\"\\n✅ Successfully upgraded CartmanLLMRoaster with Gemini API and demonstrated the FartRoastPipeline.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a91870e"
      },
      "source": [
        "import numpy as np\n",
        "from typing import Dict, Any, List\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- Access Google API Key securely ---\n",
        "# Make sure to set up GOOGLE_API_KEY in Colab secrets as per instructions.\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "if GOOGLE_API_KEY is not None:\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"✅ Google Generative AI configured successfully.\")\n",
        "else:\n",
        "    print(\"❌ GOOGLE_API_KEY not found in Colab secrets. Please set it up to proceed.\")\n",
        "    # Exit or raise error if API key is critical for further steps\n",
        "\n",
        "# Assuming MLModelStub and its subclasses are defined in a previous cell.\n",
        "# If not, they would need to be included here.\n",
        "\n",
        "# --- 1. Define CartmanLLMRoaster Stub (now with Gemini integration) ---\n",
        "class CartmanLLMRoaster:\n",
        "    \"\"\"Integrates with Google Gemini API to generate Cartman-style roasts.\"\"\"\n",
        "    def __init__(self):\n",
        "        if GOOGLE_API_KEY is None:\n",
        "            raise ValueError(\"Google API Key is not configured. Cannot initialize Gemini model.\")\n",
        "        self.model = genai.GenerativeModel('gemini-pro')\n",
        "        print(\"Initialized CartmanLLMRoaster with Gemini Model.\")\n",
        "\n",
        "    def generate_roast(self, fart_characteristics: Dict[str, Any]) -> str:\n",
        "        \"\"\"Generates a roast using the Gemini model based on fart characteristics.\"\"\"\n",
        "        # Construct a dynamic prompt for Gemini\n",
        "        fart_type = fart_characteristics.get('type', 'generic')\n",
        "        intensity = fart_characteristics.get('intensity', 'mild')\n",
        "        duration = fart_characteristics.get('duration', 'brief')\n",
        "        smell = fart_characteristics.get('smell', 'unidentifiable')\n",
        "\n",
        "        # Use ML predictions to make the roast more specific and dynamic\n",
        "        if fart_characteristics.get('svm_prediction') == 'class_A':\n",
        "            intensity = 'thunderous'\n",
        "        elif fart_characteristics.get('svm_prediction') == 'class_B':\n",
        "            intensity = 'whisper-soft'\n",
        "\n",
        "        if fart_characteristics.get('xgboost_prediction', 0) > 0.5:\n",
        "            duration = 'lingering'\n",
        "        elif fart_characteristics.get('xgboost_prediction', 0) <= 0.5:\n",
        "            duration = 'quick burst'\n",
        "\n",
        "        if fart_characteristics.get('random_forest_prediction', 0) > 1.5:\n",
        "            fart_type = 'gassy explosion'\n",
        "        else:\n",
        "            fart_type = 'modest puff'\n",
        "\n",
        "        if fart_characteristics.get('cart_prediction') is True:\n",
        "            smell = 'sulfur and regret'\n",
        "        else:\n",
        "            smell = 'fresh mountain air (not!)'\n",
        "\n",
        "        prompt_text = (\n",
        "            f\"You are Eric Cartman from South Park. Generate a short, insulting roast \"\n",
        "            f\"about a fart with the following characteristics: \"\n",
        "            f\"Type: {fart_type}, Intensity: {intensity}, Duration: {duration}, Smell: {smell}. \"\n",
        "            f\"Make it in your typical Cartman style, use some exaggeration and sarcasm, and make it sound like you're personally offended. \"\n",
        "            f\"Keep it concise, under 50 words.\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt_text)\n",
        "            # Extract and return the generated roast text\n",
        "            roast_text = response.text\n",
        "        except Exception as e:\n",
        "            roast_text = f\"Failed to generate roast with Gemini: {e}. Defaulting to fixed roast. \"\n",
        "            roast_text += f\"Oh, that was a {fart_type}, {intensity}, {duration} fart with a hint of {smell}. You need to work on your technique, fatty!\"\n",
        "\n",
        "        return roast_text\n",
        "\n",
        "# --- 2. Create the FartRoastPipeline class (copied for re-definition) ---\n",
        "class FartRoastPipeline:\n",
        "    \"\"\"A Hugging Face-like pipeline for detecting farts, classifying them with ML, and roasting them with an LLM.\"\"\"\n",
        "    def __init__(self, traditional_models: Dict[str, Any], llm_roaster: CartmanLLMRoaster):\n",
        "        self.traditional_models = traditional_models\n",
        "        self.llm_roaster = llm_roaster\n",
        "        print(\"Initialized FartRoastPipeline with ML models and LLM roaster.\")\n",
        "\n",
        "    def __call__(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        return self.generate_roast(audio_features)\n",
        "\n",
        "    def generate_roast(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"Orchestrates the ML predictions and LLM roast generation.\"\"\"\n",
        "        print(f\"\\nProcessing audio features: {audio_features}\")\n",
        "        fart_characteristics = {}\n",
        "        ml_predictions = {}\n",
        "\n",
        "        # a. Call predict method of each traditional ML model stub\n",
        "        for model_name, model_stub in self.traditional_models.items():\n",
        "            prediction = model_stub.predict(audio_features)\n",
        "            ml_predictions[f'{model_name}_prediction'] = prediction\n",
        "            print(f\"  - {model_name} prediction: {prediction}\")\n",
        "\n",
        "        # b. Aggregate predictions into fart_characteristics for LLM\n",
        "        # and c. Construct dictionary for CartmanLLMRoaster\n",
        "        fart_characteristics = {\n",
        "            'xgboost_prediction': ml_predictions.get('XGBoost Model_prediction'),\n",
        "            'svm_prediction': ml_predictions.get('SVM Model_prediction'),\n",
        "            'random_forest_prediction': ml_predictions.get('RandomForest Model_prediction'),\n",
        "            'cart_prediction': ml_predictions.get('CART Model_prediction')\n",
        "        }\n",
        "\n",
        "        # d. Call the generate_roast method of the CartmanLLMRoaster instance\n",
        "        roast_text = self.llm_roaster.generate_roast(fart_characteristics)\n",
        "        print(f\"  - LLM generated roast.\")\n",
        "\n",
        "        # e. Return results\n",
        "        return {\n",
        "            \"roast_text\": roast_text,\n",
        "            \"ml_predictions\": ml_predictions\n",
        "        }\n",
        "\n",
        "print(\"\\n--- Re-Instantiating all stubs ---\")\n",
        "# Instantiate the previously defined stub models (assuming they are in scope)\n",
        "# If not, the MLModelStub and its subclasses need to be defined here again or imported.\n",
        "\n",
        "# For this demonstration, we'll re-define them minimally if they aren't in scope\n",
        "# or assume they are still defined from previous successful execution.\n",
        "\n",
        "# Placeholder classes for demonstration if previous cells are not executed in order\n",
        "class MLModelStub:\n",
        "    def __init__(self, model_name=\"MLModel\"): self.model_name = model_name\n",
        "    def predict(self, features: np.ndarray): raise NotImplementedError(\"Predict method must be implemented by subclasses.\")\n",
        "\n",
        "class XGBoostStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"XGBoost Model\")\n",
        "    def predict(self, features: np.ndarray): return np.mean(features) + 0.1\n",
        "\n",
        "class SVMStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"SVM Model\")\n",
        "    def predict(self, features: np.ndarray): return \"class_A\" if np.sum(features) > 1.0 else \"class_B\"\n",
        "\n",
        "class RandomForestStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"RandomForest Model\")\n",
        "    def predict(self, features: np.ndarray): return np.max(features) * 2.5\n",
        "\n",
        "class CARTStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"CART Model\")\n",
        "    def predict(self, features: np.ndarray): return features[0, 0] > 0.7\n",
        "\n",
        "\n",
        "xgb_stub = XGBoostStub()\n",
        "svm_stub = SVMStub()\n",
        "rf_stub = RandomForestStub()\n",
        "cart_stub = CARTStub()\n",
        "\n",
        "# Instantiate the new CartmanLLMRoaster\n",
        "cartman_llm = CartmanLLMRoaster()\n",
        "\n",
        "print(\"\\n--- Re-Creating FartRoastPipeline instance ---\")\n",
        "pipeline_models = {\n",
        "    \"XGBoost Model\": xgb_stub,\n",
        "    \"SVM Model\": svm_stub,\n",
        "    \"RandomForest Model\": rf_stub,\n",
        "    \"CART Model\": cart_stub\n",
        "}\n",
        "fart_roast_pipeline = FartRoastPipeline(traditional_models=pipeline_models, llm_roaster=cartman_llm)\n",
        "\n",
        "# --- Prepare sample audio features ---\n",
        "sample_audio_features = np.array([[0.6, 0.3, 0.9]]) # Slightly different from previous sample_input\n",
        "print(f\"\\nSample audio features for pipeline: {sample_audio_features}\")\n",
        "\n",
        "# --- Call the FartRoastPipeline instance and print the result ---\n",
        "print(\"\\n--- Running the FartRoastPipeline ---\")\n",
        "result = fart_roast_pipeline(sample_audio_features)\n",
        "\n",
        "print(\"\\n--- Pipeline Result ---\")\n",
        "print(f\"Roast: {result['roast_text']}\")\n",
        "print(f\"ML Predictions: {result['ml_predictions']}\")\n",
        "\n",
        "print(\"\\n✅ Successfully upgraded CartmanLLMRoaster with Gemini API and demonstrated the FartRoastPipeline.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a44cf0f6"
      },
      "source": [
        "import numpy as np\n",
        "from typing import Dict, Any, List\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- Access Google API Key securely ---\n",
        "# Make sure to set up GOOGLE_API_KEY in Colab secrets as per instructions.\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "if GOOGLE_API_KEY is not None:\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"✅ Google Generative AI configured successfully.\")\n",
        "else:\n",
        "    print(\"❌ GOOGLE_API_KEY not found in Colab secrets. Please set it up to proceed.\")\n",
        "    # Exit or raise error if API key is critical for further steps\n",
        "\n",
        "# Assuming MLModelStub and its subclasses are defined in a previous cell.\n",
        "# If not, they would need to be included here.\n",
        "\n",
        "# --- 1. Define CartmanLLMRoaster Stub (now with Gemini integration) ---\n",
        "class CartmanLLMRoaster:\n",
        "    \"\"\"Integrates with Google Gemini API to generate Cartman-style roasts.\"\"\"\n",
        "    def __init__(self):\n",
        "        if GOOGLE_API_KEY is None:\n",
        "            raise ValueError(\"Google API Key is not configured. Cannot initialize Gemini model.\")\n",
        "        self.model = genai.GenerativeModel('gemini-pro')\n",
        "        print(\"Initialized CartmanLLMRoaster with Gemini Model.\")\n",
        "\n",
        "    def generate_roast(self, fart_characteristics: Dict[str, Any]) -> str:\n",
        "        \"\"\"Generates a roast using the Gemini model based on fart characteristics.\"\"\"\n",
        "        # Construct a dynamic prompt for Gemini\n",
        "        fart_type = fart_characteristics.get('type', 'generic')\n",
        "        intensity = fart_characteristics.get('intensity', 'mild')\n",
        "        duration = fart_characteristics.get('duration', 'brief')\n",
        "        smell = fart_characteristics.get('smell', 'unidentifiable')\n",
        "\n",
        "        # Use ML predictions to make the roast more specific and dynamic\n",
        "        if fart_characteristics.get('svm_prediction') == 'class_A':\n",
        "            intensity = 'thunderous'\n",
        "        elif fart_characteristics.get('svm_prediction') == 'class_B':\n",
        "            intensity = 'whisper-soft'\n",
        "\n",
        "        if fart_characteristics.get('xgboost_prediction', 0) > 0.5:\n",
        "            duration = 'lingering'\n",
        "        elif fart_characteristics.get('xgboost_prediction', 0) <= 0.5:\n",
        "            duration = 'quick burst'\n",
        "\n",
        "        if fart_characteristics.get('random_forest_prediction', 0) > 1.5:\n",
        "            fart_type = 'gassy explosion'\n",
        "        else:\n",
        "            fart_type = 'modest puff'\n",
        "\n",
        "        if fart_characteristics.get('cart_prediction') is True:\n",
        "            smell = 'sulfur and regret'\n",
        "        else:\n",
        "            smell = 'fresh mountain air (not!)'\n",
        "\n",
        "        prompt_text = (\n",
        "            f\"You are Eric Cartman from South Park. Generate a short, insulting roast \"\n",
        "            f\"about a fart with the following characteristics: \"\n",
        "            f\"Type: {fart_type}, Intensity: {intensity}, Duration: {duration}, Smell: {smell}. \"\n",
        "            f\"Make it in your typical Cartman style, use some exaggeration and sarcasm, and make it sound like you're personally offended. \"\n",
        "            f\"Keep it concise, under 50 words.\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt_text)\n",
        "            # Extract and return the generated roast text\n",
        "            roast_text = response.text\n",
        "        except Exception as e:\n",
        "            roast_text = f\"Failed to generate roast with Gemini: {e}. Defaulting to fixed roast. \"\n",
        "            roast_text += f\"Oh, that was a {fart_type}, {intensity}, {duration} fart with a hint of {smell}. You need to work on your technique, fatty!\"\n",
        "\n",
        "        return roast_text\n",
        "\n",
        "# --- 2. Create the FartRoastPipeline class (copied for re-definition) ---\n",
        "class FartRoastPipeline:\n",
        "    \"\"\"A Hugging Face-like pipeline for detecting farts, classifying them with ML, and roasting them with an LLM.\"\"\"\n",
        "    def __init__(self, traditional_models: Dict[str, Any], llm_roaster: CartmanLLMRoaster):\n",
        "        self.traditional_models = traditional_models\n",
        "        self.llm_roaster = llm_roaster\n",
        "        print(\"Initialized FartRoastPipeline with ML models and LLM roaster.\")\n",
        "\n",
        "    def __call__(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        return self.generate_roast(audio_features)\n",
        "\n",
        "    def generate_roast(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"Orchestrates the ML predictions and LLM roast generation.\"\"\"\n",
        "        print(f\"\\nProcessing audio features: {audio_features}\")\n",
        "        fart_characteristics = {}\n",
        "        ml_predictions = {}\n",
        "\n",
        "        # a. Call predict method of each traditional ML model stub\n",
        "        for model_name, model_stub in self.traditional_models.items():\n",
        "            prediction = model_stub.predict(audio_features)\n",
        "            ml_predictions[f'{model_name}_prediction'] = prediction\n",
        "            print(f\"  - {model_name} prediction: {prediction}\")\n",
        "\n",
        "        # b. Aggregate predictions into fart_characteristics for LLM\n",
        "        # and c. Construct dictionary for CartmanLLMRoaster\n",
        "        fart_characteristics = {\n",
        "            'xgboost_prediction': ml_predictions.get('XGBoost Model_prediction'),\n",
        "            'svm_prediction': ml_predictions.get('SVM Model_prediction'),\n",
        "            'random_forest_prediction': ml_predictions.get('RandomForest Model_prediction'),\n",
        "            'cart_prediction': ml_predictions.get('CART Model_prediction')\n",
        "        }\n",
        "\n",
        "        # d. Call the generate_roast method of the CartmanLLMRoaster instance\n",
        "        roast_text = self.llm_roaster.generate_roast(fart_characteristics)\n",
        "        print(f\"  - LLM generated roast.\")\n",
        "\n",
        "        # e. Return results\n",
        "        return {\n",
        "            \"roast_text\": roast_text,\n",
        "            \"ml_predictions\": ml_predictions\n",
        "        }\n",
        "\n",
        "print(\"\\n--- Re-Instantiating all stubs ---\")\n",
        "# Instantiate the previously defined stub models (assuming they are in scope)\n",
        "# If not, the MLModelStub and its subclasses need to be defined here again or imported.\n",
        "\n",
        "# For this demonstration, we'll re-define them minimally if they aren't in scope\n",
        "# or assume they are still defined from previous successful execution.\n",
        "\n",
        "# Placeholder classes for demonstration if previous cells are not executed in order\n",
        "class MLModelStub:\n",
        "    def __init__(self, model_name=\"MLModel\"): self.model_name = model_name\n",
        "    def predict(self, features: np.ndarray): raise NotImplementedError(\"Predict method must be implemented by subclasses.\")\n",
        "\n",
        "class XGBoostStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"XGBoost Model\")\n",
        "    def predict(self, features: np.ndarray): return np.mean(features) + 0.1\n",
        "\n",
        "class SVMStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"SVM Model\")\n",
        "    def predict(self, features: np.ndarray): return \"class_A\" if np.sum(features) > 1.0 else \"class_B\"\n",
        "\n",
        "class RandomForestStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"RandomForest Model\")\n",
        "    def predict(self, features: np.ndarray): return np.max(features) * 2.5\n",
        "\n",
        "class CARTStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"CART Model\")\n",
        "    def predict(self, features: np.ndarray): return features[0, 0] > 0.7\n",
        "\n",
        "\n",
        "xgb_stub = XGBoostStub()\n",
        "svm_stub = SVMStub()\n",
        "rf_stub = RandomForestStub()\n",
        "cart_stub = CARTStub()\n",
        "\n",
        "# Instantiate the new CartmanLLMRoaster\n",
        "cartman_llm = CartmanLLMRoaster()\n",
        "\n",
        "print(\"\\n--- Re-Creating FartRoastPipeline instance ---\")\n",
        "pipeline_models = {\n",
        "    \"XGBoost Model\": xgb_stub,\n",
        "    \"SVM Model\": svm_stub,\n",
        "    \"RandomForest Model\": rf_stub,\n",
        "    \"CART Model\": cart_stub\n",
        "}\n",
        "fart_roast_pipeline = FartRoastPipeline(traditional_models=pipeline_models, llm_roaster=cartman_llm)\n",
        "\n",
        "# --- Prepare sample audio features ---\n",
        "sample_audio_features = np.array([[0.6, 0.3, 0.9]]) # Slightly different from previous sample_input\n",
        "print(f\"\\nSample audio features for pipeline: {sample_audio_features}\")\n",
        "\n",
        "# --- Call the FartRoastPipeline instance and print the result ---\n",
        "print(\"\\n--- Running the FartRoastPipeline ---\")\n",
        "result = fart_roast_pipeline(sample_audio_features)\n",
        "\n",
        "print(\"\\n--- Pipeline Result ---\")\n",
        "print(f\"Roast: {result['roast_text']}\")\n",
        "print(f\"ML Predictions: {result['ml_predictions']}\")\n",
        "\n",
        "print(\"\\n✅ Successfully upgraded CartmanLLMRoaster with Gemini API and demonstrated the FartRoastPipeline.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d261d8bc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 2. Define a base Python class, MLModelStub\n",
        "class MLModelStub:\n",
        "    \"\"\"Base class for ML model stubs.\"\"\"\n",
        "    def __init__(self, model_name=\"MLModel\"):\n",
        "        self.model_name = model_name\n",
        "        print(f\"Initialized placeholder for {self.model_name}.\")\n",
        "\n",
        "    # 3. Implement the predict method within MLModelStub to raise a NotImplementedError\n",
        "    def predict(self, features: np.ndarray):\n",
        "        \"\"\"Placeholder predict method. Should be overridden by subclasses.\"\"\"\n",
        "        raise NotImplementedError(\"Predict method must be implemented by subclasses.\")\n",
        "\n",
        "# 4. Create four separate Python classes: XGBoostStub, SVMStub, RandomForestStub, and CARTStub.\n",
        "# 5. For each specific stub class, override the predict method to return a placeholder prediction.\n",
        "# 6. Add comments within each stub class.\n",
        "\n",
        "class XGBoostStub(MLModelStub):\n",
        "    \"\"\"Placeholder for an XGBoost model. In a real scenario, this would be a trained XGBoost model.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(\"XGBoost Model\")\n",
        "\n",
        "    def predict(self, features: np.ndarray):\n",
        "        # Modified: return a simple mean of the features plus a small random number\n",
        "        return np.mean(features) + np.random.uniform(-0.1, 0.1)\n",
        "\n",
        "class SVMStub(MLModelStub):\n",
        "    \"\"\"Placeholder for an SVM model. In a real scenario, this would be a trained SVM model.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(\"SVM Model\")\n",
        "\n",
        "    def predict(self, features: np.ndarray):\n",
        "        # Modified: randomly select between 'class_A' and 'class_B' with a certain probability\n",
        "        # or based on a more complex rule involving sum of features and a random threshold.\n",
        "        # Let's make it a 60/40 split for 'class_A'/'class_B' based on a random number.\n",
        "        if np.random.rand() > 0.4:\n",
        "            return \"class_A\"\n",
        "        else:\n",
        "            return \"class_B\"\n",
        "\n",
        "class RandomForestStub(MLModelStub):\n",
        "    \"\"\"Placeholder for a RandomForest model. In a real scenario, this would be a trained RandomForest model.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(\"RandomForest Model\")\n",
        "\n",
        "    def predict(self, features: np.ndarray):\n",
        "        # Modified: return a value based on the maximum feature multiplied by a random factor plus a random offset\n",
        "        return np.max(features) * np.random.uniform(2.0, 3.0) + np.random.uniform(-0.5, 0.5)\n",
        "\n",
        "class CARTStub(MLModelStub):\n",
        "    \"\"\"Placeholder for a CART (Decision Tree) model. In a real scenario, this would be a trained CART model.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(\"CART Model\")\n",
        "\n",
        "    def predict(self, features: np.ndarray):\n",
        "        # Modified: return a boolean value based on a randomly chosen threshold for one of the features,\n",
        "        # or a random boolean outcome with a certain probability.\n",
        "        # Let's make it a random boolean outcome with 70% chance of True.\n",
        "        return np.random.rand() > 0.3\n",
        "\n",
        "print(\"\\n--- Instantiating and Testing Stub Models ---\")\n",
        "\n",
        "# 7. Instantiate an object for each of the four stub models\n",
        "xgb_stub = XGBoostStub()\n",
        "svm_stub = SVMStub()\n",
        "rf_stub = RandomForestStub()\n",
        "cart_stub = CARTStub()\n",
        "\n",
        "# 8. Create a sample input feature array\n",
        "sample_input = np.array([[0.5, 0.2, 0.8]])\n",
        "print(f\"\\nSample input features: {sample_input}\")\n",
        "\n",
        "# 9. Call the predict method for each instantiated stub model and print the results\n",
        "print(f\"XGBoost Prediction: {xgb_stub.predict(sample_input)}\")\n",
        "print(f\"SVM Prediction: {svm_stub.predict(sample_input)}\")\n",
        "print(f\"RandomForest Prediction: {rf_stub.predict(sample_input)}\")\n",
        "print(f\"CART Prediction: {cart_stub.predict(sample_input)}\")\n",
        "\n",
        "print(\"\\n✅ Successfully created and tested placeholder ML model stubs.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12c814da"
      },
      "source": [
        "import numpy as np\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "# Placeholder classes for demonstration if previous cells are not executed in order\n",
        "class MLModelStub:\n",
        "    def __init__(self, model_name=\"MLModel\"): self.model_name = model_name\n",
        "    def predict(self, features: np.ndarray): raise NotImplementedError(\"Predict method must be implemented by subclasses.\")\n",
        "\n",
        "class XGBoostStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"XGBoost Model\")\n",
        "    def predict(self, features: np.ndarray):\n",
        "        return np.mean(features) + np.random.uniform(-0.1, 0.1)\n",
        "\n",
        "class SVMStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"SVM Model\")\n",
        "    def predict(self, features: np.ndarray):\n",
        "        if np.random.rand() > 0.4:\n",
        "            return \"class_A\"\n",
        "        else:\n",
        "            return \"class_B\"\n",
        "\n",
        "class RandomForestStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"RandomForest Model\")\n",
        "    def predict(self, features: np.ndarray):\n",
        "        return np.max(features) * np.random.uniform(2.0, 3.0) + np.random.uniform(-0.5, 0.5)\n",
        "\n",
        "class CARTStub(MLModelStub):\n",
        "    def __init__(self): super().__init__(\"CART Model\")\n",
        "    def predict(self, features: np.ndarray):\n",
        "        return np.random.rand() > 0.3\n",
        "\n",
        "# --- 1. Define CartmanLLMRoaster with rule-based generation ---\n",
        "class CartmanLLMRoaster:\n",
        "    \"\"\"Placeholder for the Cartman-style LLM roast generator, now with rule-based logic.\"\"\"\n",
        "    def __init__(self):\n",
        "        print(\"Initialized placeholder for CartmanLLMRoaster with rule-based logic.\")\n",
        "\n",
        "    def generate_roast(self, fart_characteristics: Dict[str, Any]) -> str:\n",
        "        \"\"\"Generates a mock roast based on fart characteristics using internal rules.\"\"\"\n",
        "        fart_type = \"modest puff\"\n",
        "        intensity = \"mild\"\n",
        "        duration = \"brief\"\n",
        "        smell = \"unidentifiable\"\n",
        "\n",
        "        # Rule-based mapping for more interesting roasts based on stub outputs\n",
        "        if fart_characteristics.get('svm_prediction') == 'class_A':\n",
        "            intensity = 'thunderous'\n",
        "        elif fart_characteristics.get('svm_prediction') == 'class_B':\n",
        "            intensity = 'whisper-soft'\n",
        "\n",
        "        if fart_characteristics.get('xgboost_prediction', 0) > 0.6:\n",
        "            duration = 'lingering'\n",
        "        elif fart_characteristics.get('xgboost_prediction', 0) < 0.4:\n",
        "            duration = 'quick burst'\n",
        "        else:\n",
        "            duration = 'average'\n",
        "\n",
        "        if fart_characteristics.get('random_forest_prediction', 0) > 2.0:\n",
        "            fart_type = 'gassy explosion'\n",
        "        elif fart_characteristics.get('random_forest_prediction', 0) < 1.0:\n",
        "            fart_type = 'tiny poot'\n",
        "        else:\n",
        "            fart_type = 'regular fart'\n",
        "\n",
        "        if fart_characteristics.get('cart_prediction') is True:\n",
        "            smell = 'sulfur and regret'\n",
        "        else:\n",
        "            smell = 'fresh mountain air (NOT!)'\n",
        "\n",
        "        roast_templates = [\n",
        "            f\"Oh, that was a {fart_type}, {intensity}, {duration} fart with a hint of {smell}. You need to work on your technique, fatty!\",\n",
        "            f\"Seriously?! A {intensity}, {duration} {fart_type} with {smell}? You disgust me, you fatass!\",\n",
        "            f\"Did you just unleash a {fart_type} that was {intensity} and {duration} with {smell}? Kyle's mom would be ashamed!\",\n",
        "            f\"Ugh, that {duration} {fart_type} with {smell} was so {intensity}, it made me want to puke. Respect my authoritah!\"\n",
        "        ]\n",
        "\n",
        "        # Choose a random roast template for more variety\n",
        "        return np.random.choice(roast_templates)\n",
        "\n",
        "# --- 2. Create the FartRoastPipeline class ---\n",
        "class FartRoastPipeline:\n",
        "    \"\"\"A Hugging Face-like pipeline for detecting farts, classifying them with ML, and roasting them with an LLM.\"\"\"\n",
        "    def __init__(self, traditional_models: Dict[str, Any], llm_roaster: CartmanLLMRoaster):\n",
        "        self.traditional_models = traditional_models\n",
        "        self.llm_roaster = llm_roaster\n",
        "        print(\"Initialized FartRoastPipeline with ML models and LLM roaster.\")\n",
        "\n",
        "    def __call__(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        return self.generate_roast(audio_features)\n",
        "\n",
        "    def generate_roast(self, audio_features: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"Orchestrates the ML predictions and LLM roast generation.\"\"\"\n",
        "        print(f\"\\nProcessing audio features: {audio_features}\")\n",
        "        fart_characteristics = {}\n",
        "        ml_predictions = {}\n",
        "\n",
        "        # a. Call predict method of each traditional ML model stub\n",
        "        for model_name, model_stub in self.traditional_models.items():\n",
        "            prediction = model_stub.predict(audio_features)\n",
        "            ml_predictions[f'{model_name}_prediction'] = prediction\n",
        "            print(f\"  - {model_name} prediction: {prediction}\")\n",
        "\n",
        "        # b. Aggregate predictions into fart_characteristics for LLM\n",
        "        # and c. Construct dictionary for CartmanLLMRoaster\n",
        "        # This mapping is simplified for stub demonstration\n",
        "        fart_characteristics = {\n",
        "            'xgboost_prediction': ml_predictions.get('XGBoost Model_prediction'),\n",
        "            'svm_prediction': ml_predictions.get('SVM Model_prediction'),\n",
        "            'random_forest_prediction': ml_predictions.get('RandomForest Model_prediction'),\n",
        "            'cart_prediction': ml_predictions.get('CART Model_prediction')\n",
        "        }\n",
        "\n",
        "        # d. Call the generate_roast method of the CartmanLLMRoaster instance\n",
        "        roast_text = self.llm_roaster.generate_roast(fart_characteristics)\n",
        "        print(f\"  - LLM generated roast.\")\n",
        "\n",
        "        # e. Return results\n",
        "        return {\n",
        "            \"roast_text\": roast_text,\n",
        "            \"ml_predictions\": ml_predictions\n",
        "        }\n",
        "\n",
        "print(\"\\n--- Instantiating all stubs ---\")\n",
        "# Instantiate the previously defined stub models\n",
        "xgb_stub = XGBoostStub()\n",
        "svm_stub = SVMStub()\n",
        "rf_stub = RandomForestStub()\n",
        "cart_stub = CARTStub()\n",
        "\n",
        "# Instantiate the new CartmanLLMRoaster\n",
        "cartman_llm = CartmanLLMRoaster()\n",
        "\n",
        "print(\"\\n--- Creating FartRoastPipeline instance ---\")\n",
        "pipeline_models = {\n",
        "    \"XGBoost Model\": xgb_stub,\n",
        "    \"SVM Model\": svm_stub,\n",
        "    \"RandomForest Model\": rf_stub,\n",
        "    \"CART Model\": cart_stub\n",
        "}\n",
        "fart_roast_pipeline = FartRoastPipeline(traditional_models=pipeline_models, llm_roaster=cartman_llm)\n",
        "\n",
        "# --- Prepare sample audio features ---\n",
        "sample_audio_features = np.array([[0.6, 0.3, 0.9]]) # Slightly different from previous sample_input\n",
        "print(f\"\\nSample audio features for pipeline: {sample_audio_features}\")\n",
        "\n",
        "# --- Call the FartRoastPipeline instance and print the result ---\n",
        "print(\"\\n--- Running the FartRoastPipeline ---\")\n",
        "result = fart_roast_pipeline(sample_audio_features)\n",
        "\n",
        "print(\"\\n--- Pipeline Result ---\")\n",
        "print(f\"Roast: {result['roast_text']}\")\n",
        "print(f\"ML Predictions: {result['ml_predictions']}\")\n",
        "\n",
        "print(\"\\n✅ Successfully designed and demonstrated the FartRoastPipeline with rule-based CartmanLLMRoaster.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.model_download('deepseek-ai/deepseek-r1/transformers/deepseek-r1-distill-qwen-1.5b/2')"
      ],
      "metadata": {
        "id": "O0q0IcGNFZAL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}